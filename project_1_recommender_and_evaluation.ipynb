{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-knitting",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id            term length_of_stay_bucket rate_plan  \\\n",
       "0         1        0  WinterVacation                 [2-3]  Standard   \n",
       "1         2        1  WinterVacation                 [2-3]  Standard   \n",
       "2         3        2  WinterVacation                 [2-3]  Standard   \n",
       "3         4        3  WinterVacation                 [4-7]  Standard   \n",
       "4         5        4  WinterVacation                 [4-7]  Standard   \n",
       "5         6        5          Easter                 [4-7]  Standard   \n",
       "6         7        6       OffSeason                 [2-3]  Standard   \n",
       "7         8        7      HighSeason                 [2-3]  Standard   \n",
       "8         9        8      HighSeason                 [2-3]  Standard   \n",
       "9         8        7      HighSeason                 [2-3]  Standard   \n",
       "10        8        8      HighSeason                 [2-3]  Standard   \n",
       "11       10        9      HighSeason                 [2-3]  Standard   \n",
       "12       11        9      HighSeason                 [2-3]  Standard   \n",
       "13       12       10      HighSeason               [8-inf]  Standard   \n",
       "14       15       11       LowSeason                 [2-3]  Standard   \n",
       "\n",
       "   room_segment n_people_bucket weekend_stay  \n",
       "0     [260-360]         [5-inf]         True  \n",
       "1     [160-260]           [3-4]         True  \n",
       "2     [160-260]           [2-2]        False  \n",
       "3       [0-160]           [3-4]         True  \n",
       "4       [0-160]           [2-2]         True  \n",
       "5     [160-260]         [5-inf]         True  \n",
       "6     [160-260]         [5-inf]         True  \n",
       "7     [160-260]           [1-1]         True  \n",
       "8       [0-160]           [1-1]         True  \n",
       "9     [160-260]           [1-1]         True  \n",
       "10      [0-160]           [1-1]         True  \n",
       "11    [260-360]           [3-4]         True  \n",
       "12    [260-360]           [3-4]         True  \n",
       "13    [360-500]           [3-4]         True  \n",
       "14    [260-360]         [5-inf]         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df['term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df['length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df['rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df['room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df['n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df['weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df['weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "display(interactions_df.head(15))\n",
    "\n",
    "print(interactions_df['room_segment'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-third",
   "metadata": {},
   "source": [
    "# Define user features based on reservations\n",
    "\n",
    "The content-based recommenders will be forecasting the probability of interaction between user and item based on user features vector and item features vector:\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    r_{u, i} = f(user\\_features, item\\_features)\n",
    "$$\n",
    "</center>\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Design numerical user features based on user reservations. Code the following method which for a given interactions DataFrame (it will be used in the fit method of the recommender) returns a DataFrame with user_id and user features as well as a list with names of user features (this will be important to select the right columns for an ML algorithm). Remember to name the columns differently than item features which you will create in the next task. Validate your features on users with several interactions (sample user ids are already given below).\n",
    "\n",
    "Ideas for user features:\n",
    "- Find the vector of most popular feature values from all user reservations and encode every feature with one-hot encoding.\n",
    "- For every reservation feature calculate the probability distribution of its values among all user's reservations.\n",
    "- For numerical buckets (length_of_stay, room_segment, n_people) you can calculate the average value for every user from their reservations (you will have to map the buckets back to numerical values before averaging them).\n",
    "\n",
    "Remember that you will have to select the best features (with the highest explanatory power). Using all above features at once would make the number of variables too large for this dataset and would also introduce too much correlations between features.\n",
    "\n",
    "You can also prepare several versions of the prepare_users_df method and test which works best in your recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "variable-jaguar",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_term_WinterVacation', 'user_term_Easter', 'user_term_OffSeason', 'user_term_HighSeason', 'user_term_LowSeason', 'user_term_MayLongWeekend', 'user_term_NewYear', 'user_term_Christmas', 'user_length_of_stay_bucket_[0-1]', 'user_length_of_stay_bucket_[2-3]', 'user_length_of_stay_bucket_[4-7]', 'user_length_of_stay_bucket_[8-inf]', 'user_rate_plan_Standard', 'user_rate_plan_Nonref', 'user_room_segment_[0-160]', 'user_room_segment_[160-260]', 'user_room_segment_[260-360]', 'user_room_segment_[360-500]', 'user_room_segment_[500-900]', 'user_n_people_bucket_[1-1]', 'user_n_people_bucket_[2-2]', 'user_n_people_bucket_[3-4]', 'user_n_people_bucket_[5-inf]', 'user_weekend_stay_True', 'user_weekend_stay_False']\n",
      "13798\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_term_WinterVacation</th>\n",
       "      <th>user_term_Easter</th>\n",
       "      <th>user_term_OffSeason</th>\n",
       "      <th>user_term_HighSeason</th>\n",
       "      <th>user_term_LowSeason</th>\n",
       "      <th>user_term_MayLongWeekend</th>\n",
       "      <th>user_term_NewYear</th>\n",
       "      <th>user_term_Christmas</th>\n",
       "      <th>user_length_of_stay_bucket_[0-1]</th>\n",
       "      <th>...</th>\n",
       "      <th>user_room_segment_[160-260]</th>\n",
       "      <th>user_room_segment_[260-360]</th>\n",
       "      <th>user_room_segment_[360-500]</th>\n",
       "      <th>user_room_segment_[500-900]</th>\n",
       "      <th>user_n_people_bucket_[1-1]</th>\n",
       "      <th>user_n_people_bucket_[2-2]</th>\n",
       "      <th>user_n_people_bucket_[3-4]</th>\n",
       "      <th>user_n_people_bucket_[5-inf]</th>\n",
       "      <th>user_weekend_stay_True</th>\n",
       "      <th>user_weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>0.037879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.036232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>96</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>706</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085828</td>\n",
       "      <td>0.031936</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051896</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.025948</td>\n",
       "      <td>0.097804</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.097804</td>\n",
       "      <td>0.069860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1736</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063218</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.091954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>7779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  user_term_WinterVacation  user_term_Easter  \\\n",
       "0           1                  0.015152               0.0   \n",
       "40         50                  0.007246               0.0   \n",
       "84         96                  0.015152               0.0   \n",
       "102       115                  0.000000               0.0   \n",
       "371       706                  0.015968               0.0   \n",
       "1383     1736                  0.005747               0.0   \n",
       "7301     7779                  0.000000               0.0   \n",
       "\n",
       "      user_term_OffSeason  user_term_HighSeason  user_term_LowSeason  \\\n",
       "0                0.113636              0.015152             0.022727   \n",
       "40               0.072464              0.050725             0.036232   \n",
       "84               0.113636              0.022727             0.007576   \n",
       "102              0.166667              0.000000             0.000000   \n",
       "371              0.085828              0.031936             0.023952   \n",
       "1383             0.080460              0.034483             0.045977   \n",
       "7301             0.083333              0.000000             0.083333   \n",
       "\n",
       "      user_term_MayLongWeekend  user_term_NewYear  user_term_Christmas  \\\n",
       "0                     0.000000           0.000000                  0.0   \n",
       "40                    0.000000           0.000000                  0.0   \n",
       "84                    0.007576           0.000000                  0.0   \n",
       "102                   0.000000           0.000000                  0.0   \n",
       "371                   0.007984           0.001996                  0.0   \n",
       "1383                  0.000000           0.000000                  0.0   \n",
       "7301                  0.000000           0.000000                  0.0   \n",
       "\n",
       "      user_length_of_stay_bucket_[0-1]  ...  user_room_segment_[160-260]  \\\n",
       "0                             0.000000  ...                     0.022727   \n",
       "40                            0.000000  ...                     0.043478   \n",
       "84                            0.045455  ...                     0.037879   \n",
       "102                           0.000000  ...                     0.083333   \n",
       "371                           0.049900  ...                     0.051896   \n",
       "1383                          0.040230  ...                     0.086207   \n",
       "7301                          0.000000  ...                     0.083333   \n",
       "\n",
       "      user_room_segment_[260-360]  user_room_segment_[360-500]  \\\n",
       "0                        0.007576                     0.007576   \n",
       "40                       0.050725                     0.036232   \n",
       "84                       0.015152                     0.007576   \n",
       "102                      0.000000                     0.000000   \n",
       "371                      0.007984                     0.007984   \n",
       "1383                     0.022989                     0.005747   \n",
       "7301                     0.041667                     0.000000   \n",
       "\n",
       "      user_room_segment_[500-900]  user_n_people_bucket_[1-1]  \\\n",
       "0                        0.007576                    0.000000   \n",
       "40                       0.000000                    0.000000   \n",
       "84                       0.000000                    0.007576   \n",
       "102                      0.000000                    0.083333   \n",
       "371                      0.000000                    0.019960   \n",
       "1383                     0.000000                    0.063218   \n",
       "7301                     0.000000                    0.000000   \n",
       "\n",
       "      user_n_people_bucket_[2-2]  user_n_people_bucket_[3-4]  \\\n",
       "0                       0.121212                    0.030303   \n",
       "40                      0.028986                    0.086957   \n",
       "84                      0.045455                    0.098485   \n",
       "102                     0.000000                    0.000000   \n",
       "371                     0.025948                    0.097804   \n",
       "1383                    0.068966                    0.034483   \n",
       "7301                    0.000000                    0.125000   \n",
       "\n",
       "      user_n_people_bucket_[5-inf]  user_weekend_stay_True  \\\n",
       "0                         0.015152                0.128788   \n",
       "40                        0.050725                0.130435   \n",
       "84                        0.015152                0.121212   \n",
       "102                       0.083333                0.000000   \n",
       "371                       0.021956                0.097804   \n",
       "1383                      0.000000                0.074713   \n",
       "7301                      0.041667                0.125000   \n",
       "\n",
       "      user_weekend_stay_False  \n",
       "0                    0.037879  \n",
       "40                   0.036232  \n",
       "84                   0.045455  \n",
       "102                  0.166667  \n",
       "371                  0.069860  \n",
       "1383                 0.091954  \n",
       "7301                 0.041667  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    users_df = interactions_df.copy()\n",
    "    #https://www.sharpsightlabs.com/blog/pandas-get-dummies/\n",
    "    users_df = pd.get_dummies(users_df)\n",
    "    users_df = users_df.drop(columns=['item_id'])\n",
    "    users_df = users_df.set_index('user_id')\n",
    "    users_df = users_df.groupby('user_id').sum()\n",
    "#     users_df = users_df.apply(lambda x: np.log(x+1))\n",
    "    users_df = users_df.div(users_df.sum(axis=1), axis=0)\n",
    "    users_df = users_df.add_prefix('user_')\n",
    "    users_df = users_df.reset_index()\n",
    "    user_features = list(users_df.columns)\n",
    "    user_features.remove('user_id')\n",
    "    return users_df, user_features\n",
    "\n",
    "def prepare_users_df_2(interactions_df):\n",
    "\n",
    "    users_df = interactions_df.copy()\n",
    "    #https://www.sharpsightlabs.com/blog/pandas-get-dummies/\n",
    "    users_df = pd.get_dummies(users_df)\n",
    "    users_df = users_df.drop(columns=['item_id'])\n",
    "    users_df = users_df.set_index('user_id')\n",
    "    users_df = users_df.add_prefix('user_')\n",
    "    users_df = users_df.reset_index()\n",
    "    user_features = list(users_df.columns)\n",
    "    user_features.remove('user_id')\n",
    "    users_df = users_df.drop_duplicates()\n",
    "    return users_df, user_features\n",
    "\n",
    "    \n",
    "\n",
    "# users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "# print(user_features)\n",
    "\n",
    "# display(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15))\n",
    "\n",
    "def prepare_users_df_3(interactions_df):\n",
    "    users_df = interactions_df.copy()\n",
    "    users_df = users_df.drop(columns=['item_id'])\n",
    "    \n",
    "    users_df.loc[users_df['term'] == 'WinterVacation', 'user_term'] = 1\n",
    "    users_df.loc[users_df['term'] == 'Easter', 'user_term'] = 2\n",
    "    users_df.loc[users_df['term'] == 'OffSeason', 'user_term'] = 3\n",
    "    users_df.loc[users_df['term'] == 'HighSeason', 'user_term'] = 4\n",
    "    users_df.loc[users_df['term'] == 'LowSeason', 'user_term'] = 5\n",
    "    users_df.loc[users_df['term'] == 'MayLongWeekend', 'user_term'] = 6\n",
    "    users_df.loc[users_df['term'] == 'NewYear', 'user_term'] = 7\n",
    "    users_df.loc[users_df['term'] == 'Christmas', 'user_term'] = 8\n",
    "    users_df.loc[users_df['length_of_stay_bucket'] == '[0-1]', 'user_length_of_stay_bucket'] = 1\n",
    "    users_df.loc[users_df['length_of_stay_bucket'] == '[2-3]', 'user_length_of_stay_bucket'] = 2\n",
    "    users_df.loc[users_df['length_of_stay_bucket'] == '[4-7]', 'user_length_of_stay_bucket'] = 3\n",
    "    users_df.loc[users_df['length_of_stay_bucket'] == '[8-inf]', 'user_length_of_stay_bucket'] = 4\n",
    "    users_df.loc[users_df['rate_plan'] == 'Standard', 'user_rate_plan'] = 1\n",
    "    users_df.loc[users_df['rate_plan'] == 'Nonref', 'user_rate_plan'] = 2\n",
    "    users_df.loc[users_df['room_segment'] == '[0-160]', 'user_room_segment'] = 1\n",
    "    users_df.loc[users_df['room_segment'] == '[160-260]', 'user_room_segment'] = 2\n",
    "    users_df.loc[users_df['room_segment'] == '[260-360]', 'user_room_segment'] = 3\n",
    "    users_df.loc[users_df['room_segment'] == '[360-500]', 'user_room_segment'] = 4\n",
    "    users_df.loc[users_df['room_segment'] == '[500-900]', 'user_room_segment'] = 5\n",
    "    users_df.loc[users_df['n_people_bucket'] == '[1-1]', 'user_n_people_bucket'] = 1\n",
    "    users_df.loc[users_df['n_people_bucket'] == '[2-2]', 'user_n_people_bucket'] = 2\n",
    "    users_df.loc[users_df['n_people_bucket'] == '[3-4]', 'user_n_people_bucket'] = 3\n",
    "    users_df.loc[users_df['n_people_bucket'] == '[5-inf]', 'user_n_people_bucket'] = 4\n",
    "    users_df.loc[users_df['weekend_stay'] == 'True', 'user_weekend_stay'] = 1\n",
    "    users_df.loc[users_df['weekend_stay'] == 'False', 'user_weekend_stay'] = 2\n",
    "    users_df = users_df.drop(columns=['term'])\n",
    "    users_df = users_df.drop(columns=['length_of_stay_bucket'])\n",
    "    users_df = users_df.drop(columns=['rate_plan'])\n",
    "    users_df = users_df.drop(columns=['room_segment'])\n",
    "    users_df = users_df.drop(columns=['n_people_bucket'])\n",
    "    users_df = users_df.drop(columns=['weekend_stay'])\n",
    "    users_df = users_df.set_index('user_id')\n",
    "    users_df = users_df.groupby('user_id').mean()\n",
    "    users_df = users_df.apply(lambda x: np.log(x+1))\n",
    "    users_df = users_df.div(users_df.sum(axis=1), axis=0)\n",
    "    users_df = users_df.reset_index()\n",
    "    user_features = list(users_df.columns)\n",
    "    user_features.remove('user_id')\n",
    "    return users_df.fillna(0), user_features\n",
    "# users_df_2, user_features_2 = prepare_users_df_2(interactions_df)\n",
    "\n",
    "# print(user_features_2)\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "print(user_features)\n",
    "print(len(users_df))\n",
    "display(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-complaint",
   "metadata": {},
   "source": [
    "# Prepare numerical item features\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code the prepare_items_df method which will be used in the recommender fit and recommend methods to map items to numerical features. This method should take the interactions_df DataFrame as input and return a DataFrame containing one record per item_id with item_id column and numerical item feature columns.\n",
    "\n",
    "You can try turning all item features into one-hot representations. You can use the get_dummies method from pandas. It will return the same columns on any dataset of interactions because the categorical variables with all possible values have been defined in the second cell in this notebook.\n",
    "\n",
    "You are welcome to design your own numerical item features, for instance based on numerical min and max values in buckets used as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formal-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_term_WinterVacation', 'item_term_Easter', 'item_term_OffSeason', 'item_term_HighSeason', 'item_term_LowSeason', 'item_term_MayLongWeekend', 'item_term_NewYear', 'item_term_Christmas', 'item_length_of_stay_bucket_[0-1]', 'item_length_of_stay_bucket_[2-3]', 'item_length_of_stay_bucket_[4-7]', 'item_length_of_stay_bucket_[8-inf]', 'item_rate_plan_Standard', 'item_rate_plan_Nonref', 'item_room_segment_[0-160]', 'item_room_segment_[160-260]', 'item_room_segment_[260-360]', 'item_room_segment_[360-500]', 'item_room_segment_[500-900]', 'item_n_people_bucket_[1-1]', 'item_n_people_bucket_[2-2]', 'item_n_people_bucket_[3-4]', 'item_n_people_bucket_[5-inf]', 'item_weekend_stay_True', 'item_weekend_stay_False']\n",
      "1063\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_term_WinterVacation</th>\n",
       "      <th>item_term_Easter</th>\n",
       "      <th>item_term_OffSeason</th>\n",
       "      <th>item_term_HighSeason</th>\n",
       "      <th>item_term_LowSeason</th>\n",
       "      <th>item_term_MayLongWeekend</th>\n",
       "      <th>item_term_NewYear</th>\n",
       "      <th>item_term_Christmas</th>\n",
       "      <th>item_length_of_stay_bucket_[0-1]</th>\n",
       "      <th>...</th>\n",
       "      <th>item_room_segment_[160-260]</th>\n",
       "      <th>item_room_segment_[260-360]</th>\n",
       "      <th>item_room_segment_[360-500]</th>\n",
       "      <th>item_room_segment_[500-900]</th>\n",
       "      <th>item_n_people_bucket_[1-1]</th>\n",
       "      <th>item_n_people_bucket_[2-2]</th>\n",
       "      <th>item_n_people_bucket_[3-4]</th>\n",
       "      <th>item_n_people_bucket_[5-inf]</th>\n",
       "      <th>item_weekend_stay_True</th>\n",
       "      <th>item_weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  item_term_WinterVacation  item_term_Easter  item_term_OffSeason  \\\n",
       "0        0                  0.166667          0.000000             0.000000   \n",
       "1        1                  0.166667          0.000000             0.000000   \n",
       "2        2                  0.166667          0.000000             0.000000   \n",
       "3        3                  0.166667          0.000000             0.000000   \n",
       "4        4                  0.166667          0.000000             0.000000   \n",
       "5        5                  0.000000          0.166667             0.000000   \n",
       "6        6                  0.000000          0.000000             0.166667   \n",
       "\n",
       "   item_term_HighSeason  item_term_LowSeason  item_term_MayLongWeekend  \\\n",
       "0                   0.0                  0.0                       0.0   \n",
       "1                   0.0                  0.0                       0.0   \n",
       "2                   0.0                  0.0                       0.0   \n",
       "3                   0.0                  0.0                       0.0   \n",
       "4                   0.0                  0.0                       0.0   \n",
       "5                   0.0                  0.0                       0.0   \n",
       "6                   0.0                  0.0                       0.0   \n",
       "\n",
       "   item_term_NewYear  item_term_Christmas  item_length_of_stay_bucket_[0-1]  \\\n",
       "0                0.0                  0.0                               0.0   \n",
       "1                0.0                  0.0                               0.0   \n",
       "2                0.0                  0.0                               0.0   \n",
       "3                0.0                  0.0                               0.0   \n",
       "4                0.0                  0.0                               0.0   \n",
       "5                0.0                  0.0                               0.0   \n",
       "6                0.0                  0.0                               0.0   \n",
       "\n",
       "   ...  item_room_segment_[160-260]  item_room_segment_[260-360]  \\\n",
       "0  ...                     0.000000                     0.166667   \n",
       "1  ...                     0.166667                     0.000000   \n",
       "2  ...                     0.166667                     0.000000   \n",
       "3  ...                     0.000000                     0.000000   \n",
       "4  ...                     0.000000                     0.000000   \n",
       "5  ...                     0.166667                     0.000000   \n",
       "6  ...                     0.166667                     0.000000   \n",
       "\n",
       "   item_room_segment_[360-500]  item_room_segment_[500-900]  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "5                          0.0                          0.0   \n",
       "6                          0.0                          0.0   \n",
       "\n",
       "   item_n_people_bucket_[1-1]  item_n_people_bucket_[2-2]  \\\n",
       "0                         0.0                    0.000000   \n",
       "1                         0.0                    0.000000   \n",
       "2                         0.0                    0.166667   \n",
       "3                         0.0                    0.000000   \n",
       "4                         0.0                    0.166667   \n",
       "5                         0.0                    0.000000   \n",
       "6                         0.0                    0.000000   \n",
       "\n",
       "   item_n_people_bucket_[3-4]  item_n_people_bucket_[5-inf]  \\\n",
       "0                    0.000000                      0.166667   \n",
       "1                    0.166667                      0.000000   \n",
       "2                    0.000000                      0.000000   \n",
       "3                    0.166667                      0.000000   \n",
       "4                    0.000000                      0.000000   \n",
       "5                    0.000000                      0.166667   \n",
       "6                    0.000000                      0.166667   \n",
       "\n",
       "   item_weekend_stay_True  item_weekend_stay_False  \n",
       "0                0.166667                 0.000000  \n",
       "1                0.166667                 0.000000  \n",
       "2                0.000000                 0.166667  \n",
       "3                0.166667                 0.000000  \n",
       "4                0.166667                 0.000000  \n",
       "5                0.166667                 0.000000  \n",
       "6                0.166667                 0.000000  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_items_df(interactions_df):\n",
    "    \n",
    "    items_df = interactions_df.copy()\n",
    "    #https://www.sharpsightlabs.com/blog/pandas-get-dummies/\n",
    "    if 'user_id' in items_df.columns:\n",
    "        items_df = items_df.drop(columns=['user_id'])\n",
    "    items_df = pd.get_dummies(items_df)  \n",
    "    items_df = items_df.set_index('item_id')\n",
    "    items_df = items_df.groupby('item_id').sum()\n",
    "#     items_df = items_df.apply(lambda x: np.log(x+1))\n",
    "    items_df = items_df.div(items_df.sum(axis=1), axis=0)\n",
    "    items_df = items_df.add_prefix('item_')\n",
    "    items_df = items_df.reset_index()\n",
    "    item_features = list(items_df.columns)\n",
    "    item_features.remove('item_id')\n",
    "    \n",
    "    return items_df, item_features\n",
    "\n",
    "def prepare_items_df_2(interactions_df):\n",
    "    \n",
    "    items_df = interactions_df.copy()\n",
    "    #https://www.sharpsightlabs.com/blog/pandas-get-dummies/\n",
    "    if 'user_id' in items_df.columns:\n",
    "        items_df = items_df.drop(columns=['user_id'])\n",
    "    items_df = pd.get_dummies(items_df)  \n",
    "#     items_df = items_df.set_index('item_id')\n",
    "#     items_df = items_df.add_prefix('item_')\n",
    "#     items_df = items_df.reset_index()\n",
    "    item_features = list(items_df.columns)\n",
    "#     item_features.remove('item_id')\n",
    "    items_df = items_df.drop_duplicates()\n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "# items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "# print(item_features)\n",
    "\n",
    "# display(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15))\n",
    "\n",
    "def prepare_items_df_3(interactions_df):\n",
    "    items_df = interactions_df.copy()\n",
    "    if 'user_id' in items_df.columns:\n",
    "        items_df = items_df.drop(columns=['user_id'])\n",
    "    \n",
    "    items_df.loc[items_df['term'] == 'WinterVacation', 'item_term'] = 1\n",
    "    items_df.loc[items_df['term'] == 'Easter', 'item_term'] = 2\n",
    "    items_df.loc[items_df['term'] == 'OffSeason', 'item_term'] = 3\n",
    "    items_df.loc[items_df['term'] == 'HighSeason', 'item_term'] = 4\n",
    "    items_df.loc[items_df['term'] == 'LowSeason', 'item_term'] = 5\n",
    "    items_df.loc[items_df['term'] == 'MayLongWeekend', 'item_term'] = 6\n",
    "    items_df.loc[items_df['term'] == 'NewYear', 'item_term'] = 7\n",
    "    items_df.loc[items_df['term'] == 'Christmas', 'item_term'] = 8\n",
    "    items_df.loc[items_df['length_of_stay_bucket'] == '[0-1]', 'item_length_of_stay_bucket'] = 1\n",
    "    items_df.loc[items_df['length_of_stay_bucket'] == '[2-3]', 'item_length_of_stay_bucket'] = 2\n",
    "    items_df.loc[items_df['length_of_stay_bucket'] == '[4-7]', 'item_length_of_stay_bucket'] = 3\n",
    "    items_df.loc[items_df['length_of_stay_bucket'] == '[8-inf]', 'item_length_of_stay_bucket'] = 4\n",
    "    items_df.loc[items_df['rate_plan'] == 'Standard', 'item_rate_plan'] = 1\n",
    "    items_df.loc[items_df['rate_plan'] == 'Nonref', 'item_rate_plan'] = 2\n",
    "    items_df.loc[items_df['room_segment'] == '[0-160]', 'item_room_segment'] = 1\n",
    "    items_df.loc[items_df['room_segment'] == '[160-260]', 'item_room_segment'] = 2\n",
    "    items_df.loc[items_df['room_segment'] == '[260-360]', 'item_room_segment'] = 3\n",
    "    items_df.loc[items_df['room_segment'] == '[360-500]', 'item_room_segment'] = 4\n",
    "    items_df.loc[items_df['room_segment'] == '[500-900]', 'item_room_segment'] = 5\n",
    "    items_df.loc[items_df['n_people_bucket'] == '[1-1]', 'item_n_people_bucket'] = 1\n",
    "    items_df.loc[items_df['n_people_bucket'] == '[2-2]', 'item_n_people_bucket'] = 2\n",
    "    items_df.loc[items_df['n_people_bucket'] == '[3-4]', 'item_n_people_bucket'] = 3\n",
    "    items_df.loc[items_df['n_people_bucket'] == '[5-inf]', 'item_n_people_bucket'] = 4\n",
    "    items_df.loc[items_df['weekend_stay'] == 'True', 'item_weekend_stay'] = 1\n",
    "    items_df.loc[items_df['weekend_stay'] == 'False', 'item_weekend_stay'] = 2\n",
    "    items_df = items_df.drop(columns=['term'])\n",
    "    items_df = items_df.drop(columns=['length_of_stay_bucket'])\n",
    "    items_df = items_df.drop(columns=['rate_plan'])\n",
    "    items_df = items_df.drop(columns=['room_segment'])\n",
    "    items_df = items_df.drop(columns=['n_people_bucket'])\n",
    "    items_df = items_df.drop(columns=['weekend_stay'])\n",
    "    items_df = items_df.set_index('item_id')\n",
    "    items_df = items_df.groupby('item_id').mean()\n",
    "    items_df = items_df.apply(lambda x: np.log(x+1))\n",
    "    items_df = items_df.div(items_df.sum(axis=1), axis=0)\n",
    "    items_df = items_df.reset_index()\n",
    "    item_features = list(items_df.columns)\n",
    "    item_features.remove('item_id')\n",
    "#     display(items_df)\n",
    "    return items_df.fillna(0), item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "print(len(items_df))\n",
    "display(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-imaging",
   "metadata": {},
   "source": [
    "# Content-based recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code the content-based recommender. User features should be calculated within the fit method based on available training data and should be saved in the object as self.users_df for later use in the recommend method. Item features should be calculated both in the fit method (from interactions_df) and in the recommend method (from items_df - the items to be evaluated).\n",
    "\n",
    "In the fit method you have to randomly generate non-existing interactions and add them to the training data for the regressor. You should add the target variable to interactions - equal to 1 for real (\"positive\") interactions and equal to 0 for those newly added \"negative\" interactions. Generate several negative interactions per every positive interaction (n_neg_per_pos). Treat the proportion as a tunable parameter of the model.\n",
    "\n",
    "Remember to keep control over randomness - in the init method add seed as a parameter and initialize the random seed generator with that seed:\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "\n",
    "Below the base content-based recommender class there are several classes which inherit from the base class and use different ML models:\n",
    "  - LinearRegressionCBUIRecommender - based on linear regression,\n",
    "  - SVRCBUIRecommender - based on Support Vector Regressor (if you want to test it, sample the data in the fit method, as the training can take many hours on the entire dataset of interactions),\n",
    "  - RandomForestCBUIRecommender - based on Random Forest,\n",
    "  - XGBoostCBUIRecommender - based on XGBoost.\n",
    "  \n",
    "There is no need to change anything in those inheriting classes, although you can experiment with other tunable parameters of the underlying models.\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - Other numerical user and item features (but always train and evaluate the model on buckets defined in the first notebook).\n",
    "  - Other ML models, e.g. Huber regression, Lasso regression, Ridge regression, LARS regression, Linear SVR, Decision Tree, Naive Bayes, LightGBM, Neural Networks or any model of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlike-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from recommenders.recommender import Recommender\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class ContentBasedUserItemRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, solver='liblinear'):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        \n",
    "#         https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions\n",
    "        self.solver=solver\n",
    "        self.model = LogisticRegression(\n",
    "            solver=self.solver) \n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        \n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = interactions_df.copy()\n",
    "        \n",
    "        # Prepare users_df and items_df\n",
    "        \n",
    "        users_df, user_features = prepare_users_df(interactions_df)\n",
    "        \n",
    "        self.users_df = users_df\n",
    "        self.user_features = user_features\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(interactions_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Generate negative interactions\n",
    "        \n",
    "        interactions_df = interactions_df.loc[:, ['user_id', 'item_id']]\n",
    "        \n",
    "        interactions_df.loc[:, 'interacted'] = 1\n",
    "        \n",
    "        negative_interactions = []\n",
    "\n",
    "        ########################\n",
    "        # Write your code here #\n",
    "        # Generate tuples (user_id, item_id, 0) for pairs (user_id, item_id) which do not\n",
    "        # appear in the interactions_df and add those tuples to the list negative_interactions.\n",
    "        # Generate self.n_neg_per_pos * len(interactions_df) negative interactions \n",
    "        # (self.n_neg_per_pos per one positive).\n",
    "        # Make sure the code is efficient and runs fast, otherwise you will not be able to properly tune your model.\n",
    "        users = list(interactions_df['user_id'].unique())\n",
    "        items = list(interactions_df['item_id'].unique())\n",
    "        for user in users:\n",
    "            user_interactions = interactions_df[interactions_df['user_id']==user]\n",
    "            random_items = self.rng.choice(items, 100)\n",
    "            user_items = list(user_interactions['item_id'].unique())\n",
    "            possible_items = list(set(random_items)-set(user_items))\n",
    "            if (len(possible_items) < self.n_neg_per_pos*len(user_interactions)):\n",
    "                random_items = self.rng.choice(items, 10000)\n",
    "                user_items = list(user_interactions['item_id'].unique())\n",
    "                possible_items = list(set(random_items)-set(user_items))\n",
    "            for i in range (self.n_neg_per_pos*len(user_interactions)):\n",
    "                negative_interactions.append((user, possible_items[i], 0))\n",
    "\n",
    "\n",
    "#         display(len(negative_interactions))\n",
    "#         print(\"Negative interactions len == 5 * interactions len: \",len(negative_interactions) == len(interactions_df)*5)\n",
    "        \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        \n",
    "        # Get the input data for the model\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "        \n",
    "        x = interactions_df.loc[:, user_features + item_features].values\n",
    "        y = interactions_df['interacted'].values\n",
    "        self.model.fit(x, y)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "        \n",
    "        ########################\n",
    "        # Write your code here #\n",
    "        # Prepare users_df and items_df\n",
    "        # For users_df you need to merge user features from self.users_df to users_df \n",
    "        # (the users for which you generate recommendations).\n",
    "        # Note that for users who were not in the hotel before (which is true for most users)\n",
    "        # there will be no features in self.users_df. For such users you can initialize their features\n",
    "        # with all zeros (for instance with fillna(0)), but you can also try to use average feature\n",
    "        # values from self.users_df (this way you would trear a new user as an average user).\n",
    "        # For items you have to apply the prepare_items_df method to items_df.\n",
    "        \n",
    "        # Score the items\n",
    "        users_df = users_df.merge(self.users_df, on=\"user_id\", how=\"left\").fillna(0)\n",
    "        items_df, item_features = prepare_items_df(items_df)\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            \n",
    "            ########################\n",
    "            # Write your code here #\n",
    "            # Create a Carthesian product of users from users_df and items from items_df\n",
    "\n",
    "            ########################\n",
    "            # Write your code here #\n",
    "            # Use self.model.predict method to calculate scores for all records in the just created DataFrame\n",
    "            # of users and items\n",
    "            \n",
    "            ########################\n",
    "            # Write your code here #\n",
    "            # Obtain item ids with the highest score and save those ids under the chosen_ids variable\n",
    "            # Do not exclude already booked items.\n",
    "            \n",
    "            \n",
    "#             interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "#             interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "        \n",
    "#             x = interactions_df.loc[:, user_features + item_features].values\n",
    "\n",
    "\n",
    "            cartesian_product = user.to_frame().T.merge(items_df, how='cross')\n",
    "#             display(cartesian_product.loc[:, user_features+item_features].values)\n",
    "            if(str(self.model)[0:18] == \"LogisticRegression\"):\n",
    "                scores = self.model.decision_function(cartesian_product.loc[:, user_features+item_features].values)\n",
    "            else:\n",
    "                scores = self.model.predict(cartesian_product.loc[:, user_features+item_features].values)\n",
    "            chosen_ids = np.argsort(-scores)[:n_recommendations]\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_id in chosen_ids:\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': item_id,\n",
    "                        'score': scores[item_id]\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df\n",
    "    \n",
    "    \n",
    "# cb_user_item_recommender = ContentBasedUserItemRecommender()\n",
    "# cb_user_item_recommender.fit(interactions_df, None, None)\n",
    "# cb_user_item_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), interactions_df, 10)\n",
    "    \n",
    "class LinearRegressionCBUIRecommender(ContentBasedUserItemRecommender):\n",
    "    \"\"\"\n",
    "    Linear regression recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, **model_params):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        super().__init__(seed=seed, n_neg_per_pos=n_neg_per_pos)\n",
    "        self.model = LinearRegression()\n",
    "        \n",
    "        \n",
    "class SVRCBUIRecommender(ContentBasedUserItemRecommender):\n",
    "    \"\"\"\n",
    "    SVR recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, **model_params):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        super().__init__(seed=seed, n_neg_per_pos=n_neg_per_pos)\n",
    "        if 'kernel' in model_params:\n",
    "            self.kernel = model_params['kernel']\n",
    "        else:\n",
    "            self.kernel = 'rbf'\n",
    "        if 'C' in model_params:\n",
    "            self.C = model_params['C']\n",
    "        else:\n",
    "            self.C = 1.0\n",
    "        if 'epsilon' in model_params:\n",
    "            self.epsilon = model_params['epsilon']\n",
    "        else:\n",
    "            self.epsilon = 0.1\n",
    "        self.model = SVR(kernel=self.kernel, C=self.C, epsilon=self.epsilon)\n",
    "        \n",
    "    \n",
    "class RandomForestCBUIRecommender(ContentBasedUserItemRecommender):\n",
    "    \"\"\"\n",
    "    Random forest recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, **model_params):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        super().__init__(seed=seed, n_neg_per_pos=n_neg_per_pos)\n",
    "        if 'n_estimators' in model_params:\n",
    "            self.n_estimators = int(model_params['n_estimators'])\n",
    "        else:\n",
    "            self.n_estimators = 100\n",
    "        if 'max_depth' in model_params:\n",
    "            self.max_depth = int(model_params['max_depth'])\n",
    "        else:\n",
    "            self.max_depth = 30\n",
    "        if 'min_samples_split' in model_params:\n",
    "            self.min_samples_split = int(model_params['min_samples_split'])\n",
    "        else:\n",
    "            self.min_samples_split = 30\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=self.n_estimators, max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "    \n",
    "    \n",
    "class XGBoostCBUIRecommender(ContentBasedUserItemRecommender):\n",
    "    \"\"\"\n",
    "    XGBoost recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5, **model_params):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        super().__init__(seed=seed, n_neg_per_pos=n_neg_per_pos)\n",
    "        if 'n_estimators' in model_params:\n",
    "            self.n_estimators = int(model_params['n_estimators'])\n",
    "        else:\n",
    "            self.n_estimators = 273\n",
    "        if 'max_depth' in model_params:\n",
    "            self.max_depth = model_params['max_depth']\n",
    "        else:\n",
    "            self.max_depth = 30\n",
    "        if 'min_samples_split' in model_params:\n",
    "            self.min_samples_split = int(model_params['min_samples_split'])\n",
    "        else:\n",
    "            self.min_samples_split = 30\n",
    "        if 'learning_rate' in model_params:\n",
    "            self.learning_rate = model_params['learning_rate']\n",
    "        else:\n",
    "            self.learning_rate = 30\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=self.n_estimators, max_depth=self.max_depth, min_samples_split=self.min_samples_split,\n",
    "            learning_rate=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-relative",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greatest-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fit time: 8.575805425643921\n"
     ]
    }
   ],
   "source": [
    "# Fit method\n",
    "import time\n",
    "t0 = time.time()\n",
    "cb_user_item_recommender = ContentBasedUserItemRecommender()\n",
    "cb_user_item_recommender.fit(interactions_df, None, None)\n",
    "print('Total fit time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "digital-consolidation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>151</td>\n",
       "      <td>2.322253</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>169</td>\n",
       "      <td>2.094631</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>93</td>\n",
       "      <td>2.090657</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>853</td>\n",
       "      <td>2.079943</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.077478</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>675</td>\n",
       "      <td>1.955381</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>199</td>\n",
       "      <td>1.863036</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>1.849857</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>237</td>\n",
       "      <td>1.848347</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1.845883</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>151</td>\n",
       "      <td>2.879084</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>169</td>\n",
       "      <td>2.651462</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>93</td>\n",
       "      <td>2.647488</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>853</td>\n",
       "      <td>2.636774</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.634309</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>2.512212</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>199</td>\n",
       "      <td>2.419867</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.406688</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>237</td>\n",
       "      <td>2.405178</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.402714</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>151</td>\n",
       "      <td>2.837393</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>169</td>\n",
       "      <td>2.609771</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>93</td>\n",
       "      <td>2.605797</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>853</td>\n",
       "      <td>2.595083</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.592619</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>675</td>\n",
       "      <td>2.470521</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>199</td>\n",
       "      <td>2.378176</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.364997</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>237</td>\n",
       "      <td>2.363487</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.361023</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>151</td>\n",
       "      <td>3.172678</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.0</td>\n",
       "      <td>169</td>\n",
       "      <td>2.945057</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.0</td>\n",
       "      <td>93</td>\n",
       "      <td>2.941083</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.0</td>\n",
       "      <td>853</td>\n",
       "      <td>2.930368</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.927904</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.0</td>\n",
       "      <td>675</td>\n",
       "      <td>2.805807</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.0</td>\n",
       "      <td>199</td>\n",
       "      <td>2.713461</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.700283</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.0</td>\n",
       "      <td>237</td>\n",
       "      <td>2.698773</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.696309</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>151</td>\n",
       "      <td>3.072136</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>169</td>\n",
       "      <td>2.844514</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.0</td>\n",
       "      <td>93</td>\n",
       "      <td>2.840540</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>853</td>\n",
       "      <td>2.829826</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.827362</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.0</td>\n",
       "      <td>675</td>\n",
       "      <td>2.705264</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.0</td>\n",
       "      <td>199</td>\n",
       "      <td>2.612919</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.599740</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.0</td>\n",
       "      <td>237</td>\n",
       "      <td>2.598230</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.595766</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id item_id     score       term length_of_stay_bucket rate_plan  \\\n",
       "0       1.0     151  2.322253  OffSeason                 [2-3]    Nonref   \n",
       "1       1.0     169  2.094631  OffSeason                 [2-3]    Nonref   \n",
       "2       1.0      93  2.090657  OffSeason                 [2-3]    Nonref   \n",
       "3       1.0     853  2.079943  OffSeason                 [2-3]    Nonref   \n",
       "4       1.0      60  2.077478  OffSeason                 [2-3]    Nonref   \n",
       "5       1.0     675  1.955381  Christmas                 [2-3]    Nonref   \n",
       "6       1.0     199  1.863036  OffSeason                 [2-3]    Nonref   \n",
       "7       1.0      58  1.849857  OffSeason                 [2-3]    Nonref   \n",
       "8       1.0     237  1.848347  OffSeason                 [2-3]    Nonref   \n",
       "9       1.0      56  1.845883  OffSeason                 [2-3]    Nonref   \n",
       "10      2.0     151  2.879084  OffSeason                 [2-3]    Nonref   \n",
       "11      2.0     169  2.651462  OffSeason                 [2-3]    Nonref   \n",
       "12      2.0      93  2.647488  OffSeason                 [2-3]    Nonref   \n",
       "13      2.0     853  2.636774  OffSeason                 [2-3]    Nonref   \n",
       "14      2.0      60  2.634309  OffSeason                 [2-3]    Nonref   \n",
       "15      2.0     675  2.512212  Christmas                 [2-3]    Nonref   \n",
       "16      2.0     199  2.419867  OffSeason                 [2-3]    Nonref   \n",
       "17      2.0      58  2.406688  OffSeason                 [2-3]    Nonref   \n",
       "18      2.0     237  2.405178  OffSeason                 [2-3]    Nonref   \n",
       "19      2.0      56  2.402714  OffSeason                 [2-3]    Nonref   \n",
       "20      3.0     151  2.837393  OffSeason                 [2-3]    Nonref   \n",
       "21      3.0     169  2.609771  OffSeason                 [2-3]    Nonref   \n",
       "22      3.0      93  2.605797  OffSeason                 [2-3]    Nonref   \n",
       "23      3.0     853  2.595083  OffSeason                 [2-3]    Nonref   \n",
       "24      3.0      60  2.592619  OffSeason                 [2-3]    Nonref   \n",
       "25      3.0     675  2.470521  Christmas                 [2-3]    Nonref   \n",
       "26      3.0     199  2.378176  OffSeason                 [2-3]    Nonref   \n",
       "27      3.0      58  2.364997  OffSeason                 [2-3]    Nonref   \n",
       "28      3.0     237  2.363487  OffSeason                 [2-3]    Nonref   \n",
       "29      3.0      56  2.361023  OffSeason                 [2-3]    Nonref   \n",
       "30      4.0     151  3.172678  OffSeason                 [2-3]    Nonref   \n",
       "31      4.0     169  2.945057  OffSeason                 [2-3]    Nonref   \n",
       "32      4.0      93  2.941083  OffSeason                 [2-3]    Nonref   \n",
       "33      4.0     853  2.930368  OffSeason                 [2-3]    Nonref   \n",
       "34      4.0      60  2.927904  OffSeason                 [2-3]    Nonref   \n",
       "35      4.0     675  2.805807  Christmas                 [2-3]    Nonref   \n",
       "36      4.0     199  2.713461  OffSeason                 [2-3]    Nonref   \n",
       "37      4.0      58  2.700283  OffSeason                 [2-3]    Nonref   \n",
       "38      4.0     237  2.698773  OffSeason                 [2-3]    Nonref   \n",
       "39      4.0      56  2.696309  OffSeason                 [2-3]    Nonref   \n",
       "40      5.0     151  3.072136  OffSeason                 [2-3]    Nonref   \n",
       "41      5.0     169  2.844514  OffSeason                 [2-3]    Nonref   \n",
       "42      5.0      93  2.840540  OffSeason                 [2-3]    Nonref   \n",
       "43      5.0     853  2.829826  OffSeason                 [2-3]    Nonref   \n",
       "44      5.0      60  2.827362  OffSeason                 [2-3]    Nonref   \n",
       "45      5.0     675  2.705264  Christmas                 [2-3]    Nonref   \n",
       "46      5.0     199  2.612919  OffSeason                 [2-3]    Nonref   \n",
       "47      5.0      58  2.599740  OffSeason                 [2-3]    Nonref   \n",
       "48      5.0     237  2.598230  OffSeason                 [2-3]    Nonref   \n",
       "49      5.0      56  2.595766  OffSeason                 [2-3]    Nonref   \n",
       "\n",
       "   room_segment n_people_bucket weekend_stay  \n",
       "0     [160-260]           [2-2]         True  \n",
       "1     [160-260]           [2-2]        False  \n",
       "2     [160-260]           [3-4]         True  \n",
       "3     [360-500]           [2-2]         True  \n",
       "4       [0-160]           [2-2]         True  \n",
       "5     [160-260]           [2-2]         True  \n",
       "6     [160-260]           [3-4]        False  \n",
       "7       [0-160]           [2-2]        False  \n",
       "8     [360-500]           [3-4]         True  \n",
       "9       [0-160]           [3-4]         True  \n",
       "10    [160-260]           [2-2]         True  \n",
       "11    [160-260]           [2-2]        False  \n",
       "12    [160-260]           [3-4]         True  \n",
       "13    [360-500]           [2-2]         True  \n",
       "14      [0-160]           [2-2]         True  \n",
       "15    [160-260]           [2-2]         True  \n",
       "16    [160-260]           [3-4]        False  \n",
       "17      [0-160]           [2-2]        False  \n",
       "18    [360-500]           [3-4]         True  \n",
       "19      [0-160]           [3-4]         True  \n",
       "20    [160-260]           [2-2]         True  \n",
       "21    [160-260]           [2-2]        False  \n",
       "22    [160-260]           [3-4]         True  \n",
       "23    [360-500]           [2-2]         True  \n",
       "24      [0-160]           [2-2]         True  \n",
       "25    [160-260]           [2-2]         True  \n",
       "26    [160-260]           [3-4]        False  \n",
       "27      [0-160]           [2-2]        False  \n",
       "28    [360-500]           [3-4]         True  \n",
       "29      [0-160]           [3-4]         True  \n",
       "30    [160-260]           [2-2]         True  \n",
       "31    [160-260]           [2-2]        False  \n",
       "32    [160-260]           [3-4]         True  \n",
       "33    [360-500]           [2-2]         True  \n",
       "34      [0-160]           [2-2]         True  \n",
       "35    [160-260]           [2-2]         True  \n",
       "36    [160-260]           [3-4]        False  \n",
       "37      [0-160]           [2-2]        False  \n",
       "38    [360-500]           [3-4]         True  \n",
       "39      [0-160]           [3-4]         True  \n",
       "40    [160-260]           [2-2]         True  \n",
       "41    [160-260]           [2-2]        False  \n",
       "42    [160-260]           [3-4]         True  \n",
       "43    [360-500]           [2-2]         True  \n",
       "44      [0-160]           [2-2]         True  \n",
       "45    [160-260]           [2-2]         True  \n",
       "46    [160-260]           [3-4]        False  \n",
       "47      [0-160]           [2-2]        False  \n",
       "48    [360-500]           [3-4]         True  \n",
       "49      [0-160]           [3-4]         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recommender method\n",
    "\n",
    "recommendations = cb_user_item_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), interactions_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(recommendations.tail(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-eleven",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "strange-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stable-theta",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            f = open(\"best_param_set.txt\", \"a\")\n",
    "            f.write(\"\\nLinearRegressionCBUIRecommender\\n\")\n",
    "            f.write(\"Best param set:\\n\" + str(best_param_set) + \"\\n losses:\\n\" + str(trials.losses()) + \"\\n trials:\\n\" + str(trials.trials))\n",
    "            f.close()\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    f = open(\"best_param_set.txt\", \"a\")\n",
    "    f.write(str(best_param_set))\n",
    "    f.close()\n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(results)\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-orbit",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your models using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dependent-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:02:25<00:00, 374.50s/trial, best loss: -0.004655099449851883]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegressionCBUIRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Recommender  HR@1  HR@3      HR@5     HR@10  NDCG@1  \\\n",
       "0  LinearRegressionCBUIRecommender   0.0   0.0  0.000339  0.003055     0.0   \n",
       "\n",
       "   NDCG@3    NDCG@5   NDCG@10  \n",
       "0     0.0  0.000131  0.000933  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'n_neg_per_pos': 0}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.choice('n_neg_per_pos', np.arange(1, 10, dtype=int))\n",
    "}\n",
    " \n",
    "best_param_set = tune_recommender(LinearRegressionCBUIRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "exclusive-river",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [58:41<00:00, 352.14s/trial, best loss: -0.10918324164198054]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ContentBasedUserItemRecommender</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>0.06721</td>\n",
       "      <td>0.120502</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>0.054634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Recommender      HR@1      HR@3     HR@5     HR@10  \\\n",
       "0  ContentBasedUserItemRecommender  0.010523  0.051256  0.06721  0.120502   \n",
       "\n",
       "     NDCG@1  NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.010523  0.0312  0.038071  0.054634  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'n_neg_per_pos': 3}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.choice('n_neg_per_pos', np.arange(1, 10, dtype=int))\n",
    "}\n",
    " \n",
    "best_param_set = tune_recommender(ContentBasedUserItemRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "palestinian-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [8:06:20<154:00:31, 5836.12s/trial, best loss: -0.039356749894202285]\n",
      "Best parameters:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-3060ea645c9f>\", line 32, in tune_recommender\n",
      "    best_param_set = fmin(loss, space=param_space, algo=tpe.suggest,\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/fmin.py\", line 540, in fmin\n",
      "    return trials.fmin(\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/base.py\", line 671, in fmin\n",
      "    return fmin(\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/fmin.py\", line 586, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/fmin.py\", line 364, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/fmin.py\", line 300, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/fmin.py\", line 178, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/home/jbiesek/.local/lib/python3.8/site-packages/hyperopt/base.py\", line 892, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"<ipython-input-11-3060ea645c9f>\", line 22, in loss\n",
      "    hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
      "  File \"/home/jbiesek/Pulpit/ContentBasedRecommender/evaluation_and_testing/testing.py\", line 102, in evaluate_train_test_split_implicit\n",
      "    recommendations = recommender.recommend(pd.DataFrame([user_id], columns=['user_id']),\n",
      "  File \"<ipython-input-5-9a08ceb323be>\", line 168, in recommend\n",
      "    scores = self.model.predict(cartesian_product.loc[:, user_features+item_features].values)\n",
      "  File \"/home/jbiesek/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 344, in predict\n",
      "    return predict(X)\n",
      "  File \"/home/jbiesek/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 361, in _dense_predict\n",
      "    return libsvm.predict(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.choice('n_neg_per_pos', np.arange(1, 10, dtype=int)),\n",
    "    'C': hp.loguniform('C', np.log(0.01), np.log(100.0))\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(SVRCBUIRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=100, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "seasonal-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [5:26:57<00:00, 196.17s/trial, best loss: -0.04739737621667372]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestCBUIRecommender</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.007236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Recommender      HR@1      HR@3      HR@5     HR@10  \\\n",
       "0  RandomForestCBUIRecommender  0.001358  0.004073  0.009165  0.016293   \n",
       "\n",
       "     NDCG@1    NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.001358  0.002849  0.004908  0.007236  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'max_depth': 6, 'min_samples_split': 8, 'n_estimators': 206, 'n_neg_per_pos': 6}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.choice('n_neg_per_pos', np.arange(1, 10, dtype=int)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(30, 300, dtype=int)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2, 10, dtype=int)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', np.arange(2, 30, dtype=int))\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(RandomForestCBUIRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=100, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "moved-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [10:50:29<00:00, 130.10s/trial, best loss: -0.12738044858231062] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_depth must be greater than zero. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-2eb3159b72c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m best_param_set = tune_recommender(XGBoostCBUIRecommender, interactions_df, items_df,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                   param_space, max_evals=300, show_progressbar=True, seed=seed)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-0fde002c7dd7>\u001b[0m in \u001b[0;36mtune_recommender\u001b[0;34m(recommender_class, interactions_df, items_df, param_space, max_evals, show_progressbar, seed)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mrecommender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbest_param_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n\u001b[0m\u001b[1;32m     48\u001b[0m         recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pulpit/ContentBasedRecommender/evaluation_and_testing/testing.py\u001b[0m in \u001b[0;36mevaluate_train_test_split_implicit\u001b[0;34m(recommender, interactions_df, items_df, seed)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Train the recommender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions_df_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Make recommendations for each user in the test set and calculate the metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-9c12dbbecdac>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, interactions_df, users_df, items_df)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interacted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_recommendations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m~/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m~/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_depth must be greater than zero. "
     ]
    }
   ],
   "source": [
    "# This tuning may take around 12 hours\n",
    "\n",
    "param_space = {\n",
    "    'n_neg_per_pos': hp.choice('n_neg_per_pos', np.arange(1, 10, dtype=int)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(10, 300, dtype=int)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2, 10, dtype=int)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', np.arange(2, 30, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.1))\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(XGBoostCBUIRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=300, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-strap",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon recommender's results. You can present results for several of your recommenders. You just need to give the class name of your recommender and its tuned parameters below. If you present results for several recommenders, you should add a separate cell for each recommender and change the names of the DataFrames containing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "given-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionRecommender</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.120502</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.060862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Recommender      HR@1      HR@3      HR@5     HR@10  \\\n",
       "0  LogisticRegressionRecommender  0.010523  0.051256  0.067549  0.120502   \n",
       "\n",
       "     NDCG@1    NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.010523  0.035911  0.042914  0.060862  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluation time: 459.3085196018219\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "cb_user_item_recommender = ContentBasedUserItemRecommender(\n",
    "    **{'n_neg_per_pos': 5})  # Initialize your recommender here with the best params from tuning\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "linear_cbui_tts_results = [['LogisticRegressionRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    cb_user_item_recommender, interactions_df, items_df))]\n",
    "\n",
    "linear_cbui_tts_results = pd.DataFrame(\n",
    "    linear_cbui_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(linear_cbui_tts_results)\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certified-scott",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoostCBUIRecommender</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.026477</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>0.014999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Recommender     HR@1      HR@3      HR@5     HR@10   NDCG@1  \\\n",
       "0  XGBoostCBUIRecommender  0.00611  0.014257  0.019009  0.026477  0.00611   \n",
       "\n",
       "     NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.010628  0.012615  0.014999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluation time: 270.2794783115387\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "cb_user_item_recommender = XGBoostCBUIRecommender(\n",
    "    **{'learning_rate': 0.04574969799814225, 'max_depth': None, 'min_samples_split': 3, 'n_estimators': 273, 'n_neg_per_pos': 4})  # Initialize your recommender here with the best params from tuning\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "linear_cbui_tts_results = [['XGBoostCBUIRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    cb_user_item_recommender, interactions_df, items_df))]\n",
    "\n",
    "linear_cbui_tts_results = pd.DataFrame(\n",
    "    linear_cbui_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(linear_cbui_tts_results)\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suited-nomination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonRecommender</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.09165</td>\n",
       "      <td>0.132043</td>\n",
       "      <td>0.185336</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.068082</td>\n",
       "      <td>0.084824</td>\n",
       "      <td>0.102078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Recommender      HR@1     HR@3      HR@5     HR@10    NDCG@1  \\\n",
       "0  AmazonRecommender  0.035981  0.09165  0.132043  0.185336  0.035981   \n",
       "\n",
       "     NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.068082  0.084824  0.102078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluation time: 247.63698625564575\n"
     ]
    }
   ],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "t0 = time.time()\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(amazon_tts_results)\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "moderate-printing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionRecommender</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.120502</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.060862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonRecommender</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.091650</td>\n",
       "      <td>0.132043</td>\n",
       "      <td>0.185336</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.068082</td>\n",
       "      <td>0.084824</td>\n",
       "      <td>0.102078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Recommender      HR@1      HR@3      HR@5     HR@10  \\\n",
       "0  LogisticRegressionRecommender  0.010523  0.051256  0.067549  0.120502   \n",
       "1              AmazonRecommender  0.035981  0.091650  0.132043  0.185336   \n",
       "\n",
       "     NDCG@1    NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.010523  0.035911  0.042914  0.060862  \n",
       "1  0.035981  0.068082  0.084824  0.102078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tts_results = pd.concat([linear_cbui_tts_results, amazon_tts_results]).reset_index(drop=True)\n",
    "display(tts_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
